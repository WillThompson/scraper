{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DOWNLOAD PROXIES FOR WEBSCRAPING\n",
    "\n",
    "This notebook is a demo for how this scraper can be used to scrape the free proxies from *https://free-proxy-list.net/* to be used in further webscraping tasks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import the Scraper functionality\n",
    "import Scraper\n",
    "\n",
    "# Define the routine for obtaining proxies from the *https://free-proxy-list.net/*\n",
    "from selenium.webdriver.support.ui import Select\n",
    "from bs4 import BeautifulSoup\n",
    "\n",
    "# The link that we will scrape.\n",
    "link = 'https://free-proxy-list.net/'\n",
    "\n",
    "# Define the scraper routine that you will use at the link\n",
    "# INPUT: the selenium browser instance that will be used to read the link.\n",
    "# RETURN: a pandas dataframe containing the data you want to collect.\n",
    "def scrape_routine_proxies(browser):\n",
    "    \n",
    "    # Select the option for the most numerous proxies\n",
    "    select = Select(browser.find_element_by_xpath('/html/body/section[1]/div/div[2]/div/div[1]/div[1]/div/label/select'))\n",
    "    elem = select.select_by_visible_text('80')\n",
    "\n",
    "    # Read the table and return a dataframe\n",
    "    soup = BeautifulSoup(browser.page_source,'html.parser')\n",
    "    table = soup.find('table', {'id' :\"proxylisttable\"})\n",
    "    \n",
    "    headers = [h.text for h in table.find_all('th',{'aria-controls':\"proxylisttable\"})]\n",
    "    rows = table.find_all('tr', {'class': \"odd\"}) + table.find_all('tr', {'class': \"even\"})\n",
    "    row_data = zip(*[[r.text for r in R.find_all('td')] for R in rows])\n",
    "    \n",
    "    return pd.DataFrame({a:b for (a,b) in zip(headers,row_data)})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Scrape the web proxies, then close the scraper object\n",
    "scr = Scraper.Scraper(isHeadless=True)\n",
    "df = scr.scrape_link(link,scrape_routine_proxies)\n",
    "scr.close()\n",
    "\n",
    "# properly format the columns for postgresql (i.e. lower case headers, no spaces.)\n",
    "df.columns = [header.lower().replace(\" \",\"_\") for header in df.columns]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ip_address</th>\n",
       "      <th>port</th>\n",
       "      <th>code</th>\n",
       "      <th>country</th>\n",
       "      <th>anonymity</th>\n",
       "      <th>google</th>\n",
       "      <th>https</th>\n",
       "      <th>last_checked</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.207.102.103</td>\n",
       "      <td>8080</td>\n",
       "      <td>TH</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>transparent</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>1 minute ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>51.158.102.56</td>\n",
       "      <td>80</td>\n",
       "      <td>FR</td>\n",
       "      <td>France</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>no</td>\n",
       "      <td>yes</td>\n",
       "      <td>3 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>203.107.135.125</td>\n",
       "      <td>80</td>\n",
       "      <td>TH</td>\n",
       "      <td>Thailand</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>159.203.20.110</td>\n",
       "      <td>8080</td>\n",
       "      <td>CA</td>\n",
       "      <td>Canada</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 minutes ago</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>104.248.115.226</td>\n",
       "      <td>8080</td>\n",
       "      <td>US</td>\n",
       "      <td>United States</td>\n",
       "      <td>anonymous</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>3 minutes ago</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "        ip_address  port code        country    anonymity google https  \\\n",
       "0   14.207.102.103  8080   TH       Thailand  transparent     no    no   \n",
       "1    51.158.102.56    80   FR         France    anonymous     no   yes   \n",
       "2  203.107.135.125    80   TH       Thailand    anonymous     no    no   \n",
       "3   159.203.20.110  8080   CA         Canada    anonymous     no    no   \n",
       "4  104.248.115.226  8080   US  United States    anonymous     no    no   \n",
       "\n",
       "    last_checked  \n",
       "0   1 minute ago  \n",
       "1  3 minutes ago  \n",
       "2  3 minutes ago  \n",
       "3  3 minutes ago  \n",
       "4  3 minutes ago  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# CREATE A POSTGRES TABLE TO STORE THESE PROXIES FOR USE LATER\n",
    "from sqlalchemy import create_engine, Column, Integer, String, DateTime\n",
    "from sqlalchemy.ext.declarative import declarative_base\n",
    "from sqlalchemy.engine.url import URL\n",
    "import db_configuration\n",
    "\n",
    "DB_CONFIG_DICT = db_configuration.DB_CONFIG_DICT\n",
    "DB_CONFIG_DICT['database'] = 'wills_db'\n",
    "\n",
    "DB_CONN_FORMAT = \"postgresql://{user}:{password}@{host}:{port}/{database}\"\n",
    "DB_CONN_URI_DEFAULT = (DB_CONN_FORMAT.format(**DB_CONFIG_DICT))\n",
    "\n",
    "# Create a function for a quick connection to the database\n",
    "def db_connect():\n",
    "    return create_engine(DB_CONN_URI_DEFAULT)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Use pandas functionality to upload the proxies to a postgresDB\n",
    "conn = db_connect()\n",
    "conn.execute(\"DROP TABLE IF EXISTS proxies;\")\n",
    "df.to_sql('proxies',conn,index=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('51.158.102.56', '80', 'FR', 'France', 'anonymous', 'no', 'yes', '3 minutes ago'),\n",
       " ('203.107.135.125', '80', 'TH', 'Thailand', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('159.203.20.110', '8080', 'CA', 'Canada', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('104.248.115.226', '8080', 'US', 'United States', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('157.230.149.54', '80', 'US', 'United States', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('157.230.157.60', '8080', 'US', 'United States', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('212.126.120.170', '8080', 'IQ', 'Iraq', 'anonymous', 'no', 'yes', '3 minutes ago'),\n",
       " ('68.183.39.251', '8080', 'GB', 'United Kingdom', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('157.230.236.97', '8080', 'US', 'United States', 'anonymous', 'no', 'no', '3 minutes ago'),\n",
       " ('67.198.189.239', '8888', 'US', 'United States', 'anonymous', 'no', 'no', '3 minutes ago')]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Confirm that the proxies are in the postgres DB:\n",
    "conn.execute(\"SELECT * FROM proxies WHERE anonymity = 'anonymous';\").fetchall()[0:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the execution of this notebook, I have a new set of proxy IP addresses in a postgres database that I can use to scrape data. \n",
    "\n",
    "*Don't be a jerk. Don't scrape too much, too fast: Throttle your scraper*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
